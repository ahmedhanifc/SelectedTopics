{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "50d69739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf13d01",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4b9dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for path in glob.glob(\"./names/*.txt\"):\n",
    "    nationality = os.path.basename(path).replace(\".txt\",\"\")\n",
    "\n",
    "    with open(path, encoding = \"utf-8\") as f:\n",
    "        for line in f:\n",
    "            name = line.strip()\n",
    "            if name:\n",
    "                data.append({\"Name\":line.strip(), \"Nationality\":nationality})\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "38ec6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abl</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alt</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antonowitsch</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Nationality\n",
       "0           Abl       Czech\n",
       "1         Adsit       Czech\n",
       "2        Ajdrna       Czech\n",
       "3           Alt       Czech\n",
       "4  Antonowitsch       Czech"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31b60953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nationality to numbers\n",
    "nationalities = df['Nationality'].unique()\n",
    "nationality_to_index = {}\n",
    "index_to_nationality = []\n",
    "\n",
    "current_idx = 0\n",
    "for nat in nationalities:\n",
    "    nationality_to_index[nat] = current_idx\n",
    "    index_to_nationality.append(nat)\n",
    "    current_idx = current_idx + 1\n",
    "\n",
    "labels = []\n",
    "for nat in df['Nationality']:\n",
    "    labels.append(nationality_to_index[nat])\n",
    "target_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "72c59ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20074, 2)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca952a7",
   "metadata": {},
   "source": [
    "# eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8886f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nationality\n",
       "Russian       9408\n",
       "English       3668\n",
       "Arabic        2000\n",
       "Japanese       991\n",
       "German         724\n",
       "Italian        709\n",
       "Czech          519\n",
       "Spanish        298\n",
       "Dutch          297\n",
       "French         277\n",
       "Chinese        268\n",
       "Irish          232\n",
       "Greek          203\n",
       "Polish         139\n",
       "Scottish       100\n",
       "Korean          94\n",
       "Portuguese      74\n",
       "Vietnamese      73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Nationality\"].value_counts() # HUGE IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "da8fa611",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 500\n",
    "balanced_list = []\n",
    "\n",
    "for nationality in df['Nationality'].unique():\n",
    "    subset = df[df['Nationality'] == nationality]\n",
    "    if len(subset) > target_size:\n",
    "        subset = subset.sample(n=target_size, random_state=1)\n",
    "    balanced_list.append(subset)\n",
    "\n",
    "df = pd.concat(balanced_list)\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4733d7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nationality\n",
       "German        500\n",
       "Arabic        500\n",
       "Russian       500\n",
       "Czech         500\n",
       "Italian       500\n",
       "Japanese      500\n",
       "English       500\n",
       "Spanish       298\n",
       "Dutch         297\n",
       "French        277\n",
       "Chinese       268\n",
       "Irish         232\n",
       "Greek         203\n",
       "Polish        139\n",
       "Scottish      100\n",
       "Korean         94\n",
       "Portuguese     74\n",
       "Vietnamese     73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Nationality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b605a708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Straub</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marquardt</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Palladino</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xing</td>\n",
       "      <td>Chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O'Brien</td>\n",
       "      <td>Irish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Nationality\n",
       "0     Straub      German\n",
       "1  Marquardt      German\n",
       "2  Palladino     Italian\n",
       "3       Xing     Chinese\n",
       "4    O'Brien       Irish"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47ccbbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5555, 2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8a8cd",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c17875",
   "metadata": {},
   "source": [
    "- Character-to-Index Conversion: Each character in a name is mapped to an index based on a predefined vocabulary.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ec26d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters\n",
    "\n",
    "char_to_index = {}\n",
    "char_to_index[\"<PAD>\"] = 0\n",
    "char_to_index[\"<SOS>\"] = 1\n",
    "char_to_index[\"<EOS>\"] = 2\n",
    "\n",
    "current_index = 3\n",
    "for char in all_letters:\n",
    "    char_to_index[char] = current_index\n",
    "    current_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e626f40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " 'a': 3,\n",
       " 'b': 4,\n",
       " 'c': 5,\n",
       " 'd': 6,\n",
       " 'e': 7,\n",
       " 'f': 8,\n",
       " 'g': 9,\n",
       " 'h': 10,\n",
       " 'i': 11,\n",
       " 'j': 12,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'm': 15,\n",
       " 'n': 16,\n",
       " 'o': 17,\n",
       " 'p': 18,\n",
       " 'q': 19,\n",
       " 'r': 20,\n",
       " 's': 21,\n",
       " 't': 22,\n",
       " 'u': 23,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'x': 26,\n",
       " 'y': 27,\n",
       " 'z': 28,\n",
       " 'A': 29,\n",
       " 'B': 30,\n",
       " 'C': 31,\n",
       " 'D': 32,\n",
       " 'E': 33,\n",
       " 'F': 34,\n",
       " 'G': 35,\n",
       " 'H': 36,\n",
       " 'I': 37,\n",
       " 'J': 38,\n",
       " 'K': 39,\n",
       " 'L': 40,\n",
       " 'M': 41,\n",
       " 'N': 42,\n",
       " 'O': 43,\n",
       " 'P': 44,\n",
       " 'Q': 45,\n",
       " 'R': 46,\n",
       " 'S': 47,\n",
       " 'T': 48,\n",
       " 'U': 49,\n",
       " 'V': 50,\n",
       " 'W': 51,\n",
       " 'X': 52,\n",
       " 'Y': 53,\n",
       " 'Z': 54}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd1306",
   "metadata": {},
   "source": [
    "- Padding: Names are padded to a consistent length to ensure they have the same dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dace1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_name(name):\n",
    "    return len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "67d8f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_of_name = df[\"Name\"].apply(get_length_of_name).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "54eca780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_indices(name, max_len):\n",
    "    result = []\n",
    "\n",
    "    for char in name:\n",
    "        if char in char_to_index:\n",
    "            index_value = char_to_index[char]\n",
    "            result.append(index_value)\n",
    "\n",
    "    # Padding\n",
    "    while len(result) < max_len:\n",
    "        result.append(0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7bf158d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_names = []\n",
    "for name in df[\"Name\"]:\n",
    "    encoded_list = name_to_indices(name, max_length_of_name)\n",
    "    encoded_names.append(encoded_list)\n",
    "\n",
    "labels_list = []\n",
    "for nat in df['Nationality']:\n",
    "    labels_list.append(nationality_to_index[nat])\n",
    "\n",
    "input_tensor = torch.tensor(encoded_names, dtype=torch.long)\n",
    "target_tensor = torch.tensor(labels_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b0f03708",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_tensor, target_tensor, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "72e32fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Encoded_Name'] = encoded_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8d3614ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Encoded_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Straub</td>\n",
       "      <td>German</td>\n",
       "      <td>[47, 22, 20, 3, 23, 4, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marquardt</td>\n",
       "      <td>German</td>\n",
       "      <td>[41, 3, 20, 19, 23, 3, 20, 6, 22, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Palladino</td>\n",
       "      <td>Italian</td>\n",
       "      <td>[44, 3, 14, 14, 3, 6, 11, 16, 17, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xing</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>[52, 11, 16, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O'Brien</td>\n",
       "      <td>Irish</td>\n",
       "      <td>[43, 30, 20, 11, 7, 16, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Nationality                                       Encoded_Name\n",
       "0     Straub      German  [47, 22, 20, 3, 23, 4, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
       "1  Marquardt      German  [41, 3, 20, 19, 23, 3, 20, 6, 22, 0, 0, 0, 0, ...\n",
       "2  Palladino     Italian  [44, 3, 14, 14, 3, 6, 11, 16, 17, 0, 0, 0, 0, ...\n",
       "3       Xing     Chinese  [52, 11, 16, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4    O'Brien       Irish  [43, 30, 20, 11, 7, 16, 0, 0, 0, 0, 0, 0, 0, 0..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cf984",
   "metadata": {},
   "source": [
    "- Character Embeddings: The character indices are transformed into dense vectors using an embedding layer. This helps capture more nuanced information about the characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "50c79978",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_index) \n",
    "embedding_dim = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c9c0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings=vocab_size, \n",
    "                               embedding_dim=embedding_dim, \n",
    "                               padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3eb48cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "for encoded_name in df['Encoded_Name']:\n",
    "    all_rows.append(encoded_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b2aee6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor(all_rows, dtype=torch.long)\n",
    "embedded_output = embedding_layer(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9fc01165",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name = df['Name'][0]\n",
    "first_letter_vector = embedded_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4fe9bcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Straub'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "17bc4395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3659, -0.7645,  0.3487,  0.0278, -0.8061,  0.3338,  0.5660, -1.7055,\n",
       "         0.8877,  0.0146,  0.9174,  1.0222,  0.8110,  0.3444, -0.8231,  0.8194],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_letter_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50234f",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc6bc6",
   "metadata": {},
   "source": [
    "- Multi-Layer Perceptron (MLP) <br>\n",
    "-- Embedding Layer: Transforms character indices into dense vectors. <br>\n",
    "-- Fully Connected Layer: Flattens the embeddings and passes them through a linear layer to generate predictions. <br>\n",
    "-- Output Layer: Produces probability scores for each nationality. \n",
    "\n",
    "The model is trained using cross-entropy loss and optimized with the Adam optimizer. After training, the model can predict the nationality of new names based on the learned patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ba782aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, sequence_length, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.fc1 = nn.Linear(embed_dim * sequence_length, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "       \n",
    "        \n",
    "        x = self.embedding(x) # shape: [batch_size, sequence_length, embed_dim]\n",
    "        x = x.view(x.size(0), -1) # shape: [batch_size, sequence_length * embed_dim]\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "696bb34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(\n",
    "    vocab_size=len(char_to_index),\n",
    "    embed_dim=16,\n",
    "    sequence_length=max_length_of_name,\n",
    "    num_classes=len(nationalities)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5d42d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ea8a9e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 2.8159\n",
      "Epoch [10/100], Loss: 2.7040\n",
      "Epoch [15/100], Loss: 2.6007\n",
      "Epoch [20/100], Loss: 2.5054\n",
      "Epoch [25/100], Loss: 2.4169\n",
      "Epoch [30/100], Loss: 2.3327\n",
      "Epoch [35/100], Loss: 2.2512\n",
      "Epoch [40/100], Loss: 2.1720\n",
      "Epoch [45/100], Loss: 2.0955\n",
      "Epoch [50/100], Loss: 2.0214\n",
      "Epoch [55/100], Loss: 1.9504\n",
      "Epoch [60/100], Loss: 1.8828\n",
      "Epoch [65/100], Loss: 1.8189\n",
      "Epoch [70/100], Loss: 1.7585\n",
      "Epoch [75/100], Loss: 1.7015\n",
      "Epoch [80/100], Loss: 1.6475\n",
      "Epoch [85/100], Loss: 1.5961\n",
      "Epoch [90/100], Loss: 1.5474\n",
      "Epoch [95/100], Loss: 1.5008\n",
      "Epoch [100/100], Loss: 1.4562\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_tensor)\n",
    "    loss = criterion(outputs, target_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    #Update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0e7c8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(name):\n",
    "    indices = name_to_indices(name, max_length_of_name)\n",
    "    test_tensor = torch.tensor([indices], dtype=torch.long)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(test_tensor)\n",
    "\n",
    "    scores = output[0]\n",
    "    top_values, top_indices = torch.topk(scores, k=3)\n",
    "    print(f\"name = '{name}'\\n\")\n",
    "    for i in range(3):\n",
    "        score = top_values[i].item()     \n",
    "        idx = top_indices[i].item()       \n",
    "        nat = index_to_nationality[idx]   \n",
    "        print(f\"({score:.2f}) {nat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f3b51582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = 'karima'\n",
      "\n",
      "(2.68) Arabic\n",
      "(0.87) Japanese\n",
      "(0.63) Spanish\n"
     ]
    }
   ],
   "source": [
    "predict(\"karima\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd87cba3",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cf20e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 58.06%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "    for i in range(len(y_test)):\n",
    "        if predicted[i] == y_test[i]:\n",
    "            correct = correct + 1\n",
    "        total = total + 1\n",
    "accuracy = (correct / total) * 100\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495465c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
