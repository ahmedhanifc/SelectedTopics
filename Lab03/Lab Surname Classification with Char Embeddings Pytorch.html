<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>















    




    
    
    
    




<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput">
<h3><strong>Lab Activity: Predicting Nationality from Names using Machine Learning</strong><a rel="noopener" class="anchor-link" href="#Lab-Activity:-Predicting-Nationality-from-Names-using-Machine-Learning">&#182;</a></h3><h4><strong>1. Data</strong><a rel="noopener" class="anchor-link" href="#1.-Data">&#182;</a></h4><p>For this lab activity, we will use a dataset containing names from various nationalities. The dataset is organized into different text files, each corresponding to a specific nationality. For example, you might have files named <code>English.txt</code>, <code>French.txt</code>, etc. Each file contains a list of names from that nationality.</p>
<h4><strong>2. Representation</strong><a rel="noopener" class="anchor-link" href="#2.-Representation">&#182;</a></h4><p>To train our machine learning model, we need to convert the names into a numerical format. Here are the key steps for data representation:</p>
<ul>
<li><strong>Character-to-Index Conversion</strong>: Each character in a name is mapped to an index based on a predefined vocabulary.</li>
<li><strong>Padding</strong>: Names are padded to a consistent length to ensure they have the same dimensions.</li>
<li><strong>Character Embeddings</strong>: The character indices are transformed into dense vectors using an embedding layer. This helps capture more nuanced information about the characters.</li>
</ul>
<h4><strong>3. Prediction Model</strong><a rel="noopener" class="anchor-link" href="#3.-Prediction-Model">&#182;</a></h4><p>We will use a Multi-Layer Perceptron (MLP) for predicting the nationality of a given name. Here’s a brief overview of the model architecture:</p>
<ul>
<li><strong>Embedding Layer</strong>: Transforms character indices into dense vectors.</li>
<li><strong>Fully Connected Layer</strong>: Flattens the embeddings and passes them through a linear layer to generate predictions.</li>
<li><strong>Output Layer</strong>: Produces probability scores for each nationality.</li>
</ul>
<p>The model is trained using cross-entropy loss and optimized with the Adam optimizer. After training, the model can predict the nationality of new names based on the learned patterns.</p>
<h4><strong>4. Tuning the model</strong><a rel="noopener" class="anchor-link" href="#4.-Tuning-the-model">&#182;</a></h4><p>Try different values for embedding layer, fully connected layer. Report your best results.</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&#160;[36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor">
     <div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># needed imports</span>

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="k">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="k">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="nn">ticker</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput">
<h2>Expected Output<a rel="noopener" class="anchor-link" href="#Expected-Output">&#182;</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput">
<p>name = &#39;karima&#39;</p>
<p>(5.57) Arabic</p>
<p>(4.39) Japanese</p>
<p>(2.00) Russian</p>

</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&#160;[&#160;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor">
     <div class="CodeMirror cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div>









<script type="module" src="https://s.brightspace.com/lib/bsi/2026.1.206/unbundled/mathjax.js"></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() {
					if (document.querySelector('math, .d2l-element, .d2l-cplus-layout') || /\$\$|\\\(|\\\[|\\begin{|\\ref{|\\eqref{/.test(document.body.innerHTML)) {
						document.querySelectorAll('mspace[linebreak="newline"]').forEach(elm => {
							elm.setAttribute('style', 'display: block; height: 0.5rem;');
						});

						document.querySelectorAll('math mmultiscripts > none').forEach(elm => {
							const mrow = document.createElementNS('http://www.w3.org/1998/Math/MathML', 'mrow');
							elm.replaceWith(mrow);
						});

						window.D2L.MathJax.loadMathJax({
							outputScale: 1.5,
							renderLatex: true,
							enableMML3Support: false
						});
					}
				});</script><script type="module" src="https://s.brightspace.com/lib/bsi/2026.1.206/unbundled/prism.js"></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() {
					document.querySelectorAll('.d2l-code').forEach(code => {
						window.D2L.Prism.formatCodeElement(code);
					});
				});</script><script type="module" src="https://s.brightspace.com/lib/bsi/2026.1.206/unbundled/embeds.js"></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() {
					window.D2L.EmbedRenderer.renderEmbeds(document.body);
				});</script></body></html>